

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>varnishd &mdash; Varnish version 3.0.2 documentation</title>
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.0.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Varnish version 3.0.2 documentation" href="../index.html" />
    <link rel="up" title="The Varnish Reference Manual" href="index.html" />
    <link rel="next" title="varnishhist" href="varnishhist.html" />
    <link rel="prev" title="varnishadm" href="varnishadm.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="varnishhist.html" title="varnishhist"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="varnishadm.html" title="varnishadm"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Varnish version 3.0.2 documentation</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">The Varnish Reference Manual</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="varnishd">
<h1>varnishd<a class="headerlink" href="#varnishd" title="Permalink to this headline">¶</a></h1>
<div class="section" id="http-accelerator-daemon">
<h2>HTTP accelerator daemon<a class="headerlink" href="#http-accelerator-daemon" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Author:</th><td class="field-body">Dag-Erling Smørgrav</td>
</tr>
<tr class="field"><th class="field-name">Author:</th><td class="field-body">Stig Sandbeck Mathisen</td>
</tr>
<tr class="field"><th class="field-name">Author:</th><td class="field-body">Per Buer</td>
</tr>
<tr class="field"><th class="field-name">Date:</th><td class="field-body">2010-05-31</td>
</tr>
<tr class="field"><th class="field-name">Version:</th><td class="field-body">1.0</td>
</tr>
<tr class="field"><th class="field-name">Manual section:</th><td class="field-body">1</td>
</tr>
</tbody>
</table>
<div class="section" id="synopsis">
<h3>SYNOPSIS<a class="headerlink" href="#synopsis" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>varnishd [-a address[:port]] [-b host[:port]] [-d] [-F] [-f config]</dt>
<dd>[-g group] [-h type[,options]] [-i identity]
[-l shmlogsize] [-n name] [-P file] [-p param=value]
[-s type[,options]] [-T address[:port]] [-t ttl]
[-u user] [-V] [-w min[,max[,timeout]]]</dd>
</dl>
</div>
<div class="section" id="description">
<h3>DESCRIPTION<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h3>
<p>The varnishd daemon accepts HTTP requests from clients, passes them on to a backend server and caches the
returned documents to better satisfy future requests for the same document.</p>
</div>
<div class="section" id="options">
<h3>OPTIONS<a class="headerlink" href="#options" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>-a address[:port][,address[:port][...]</dt>
<dd>Listen for client requests on the specified address and port.  The address can be a host
name (“localhost”), an IPv4 dotted-quad (“127.0.0.1”), or an IPv6 address enclosed in
square brackets (“[::1]”).  If address is not specified, varnishd will listen on all
available IPv4 and IPv6 interfaces.  If port is not specified, the default HTTP port as
listed in /etc/services is used.  Multiple listening addresses and ports can be speci‐
fied as a whitespace- or comma-separated list.</dd>
<dt>-b host[:port]</dt>
<dd>Use the specified host as backend server.  If port is not specified,
the default is 8080.</dd>
</dl>
<table class="docutils option-list" frame="void" rules="none">
<col class="option" />
<col class="description" />
<tbody valign="top">
<tr><td class="option-group">
<kbd><span class="option">-C</span></kbd></td>
<td>Print VCL code compiled to C language and exit. Specify the VCL file
to compile with the -f option.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-d</span></kbd></td>
<td>Enables debugging mode: The parent process runs in the foreground with a CLI connection
on stdin/stdout, and the child process must be started explicitly with a CLI command.
Terminating the parent process will also terminate the child.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-F</span></kbd></td>
<td>Run in the foreground.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-f <var>config</var></span></kbd></td>
<td>Use the specified VCL configuration file instead of the
builtin default.  See vcl(7) for details on VCL
syntax. When no configuration is supplied varnishd will
not start the cache process.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-g <var>group</var></span></kbd></td>
<td>Specifies the name of an unprivileged group to which the child process should switch
before it starts accepting connections.  This is a shortcut for specifying the group
run-time parameter.</td></tr>
</tbody>
</table>
<dl class="docutils">
<dt>-h type[,options]</dt>
<dd>Specifies the hash algorithm.  See Hash Algorithms for a list of supported algorithms.</dd>
</dl>
<table class="docutils option-list" frame="void" rules="none">
<col class="option" />
<col class="description" />
<tbody valign="top">
<tr><td class="option-group">
<kbd><span class="option">-i <var>identity</var></span></kbd></td>
<td>Specify the identity of the varnish server.  This can be accessed using server.identity
from VCL</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-l <var>shmlogsize</var></span></kbd></td>
<td>Specify size of shmlog file.  Scaling suffixes like 'k', 'm' can be used up to
(e)tabytes.  Default is 80 Megabytes.  Specifying less than 8 Megabytes is unwise.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-n <var>name</var></span></kbd></td>
<td>Specify a name for this instance.  Amonst other things, this name is used to construct
the name of the directory in which varnishd keeps temporary files and persistent state.
If the specified name begins with a forward slash, it is interpreted as the absolute
path to the directory which should be used for this purpose.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-P <var>file</var></span></kbd></td>
<td>Write the process's PID to the specified file.</td></tr>
</tbody>
</table>
<dl class="docutils">
<dt>-p param=value</dt>
<dd>Set the parameter specified by param to the specified value.  See Run-Time
Parameters for a list of parameters. This option can be used multiple
times to specify multiple parameters.</dd>
</dl>
<table class="docutils option-list" frame="void" rules="none">
<col class="option" />
<col class="description" />
<tbody valign="top">
<tr><td class="option-group">
<kbd><span class="option">-S <var>file</var></span></kbd></td>
<td>Path to a file containing a secret used for authorizing access to the management port.</td></tr>
</tbody>
</table>
<dl class="docutils">
<dt>-s [name=]type[,options]</dt>
<dd>Use the specified storage backend.  See Storage Types for a list of supported storage
types.  This option can be used multiple times to specify multiple storage files. You
can name the different backends. Varnish will then reference that backend with the
given name in logs, statistics, etc.</dd>
<dt>-T address[:port]</dt>
<dd>Offer a management interface on the specified address and port.  See Management
Interface for a list of management commands.</dd>
<dt>-M address:port</dt>
<dd>Connect to this port and offer the command line
interface. Think of it as a reverse shell. When running with
-M and there is no backend defined the child process (the cache)
will not start initially.</dd>
</dl>
<table class="docutils option-list" frame="void" rules="none">
<col class="option" />
<col class="description" />
<tbody valign="top">
<tr><td class="option-group">
<kbd><span class="option">-t <var>ttl</var></span></kbd></td>
<td>Specifies a hard minimum time to live for cached
documents.  This is a shortcut for specifying the
default_ttl run-time parameter.</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-u <var>user</var></span></kbd></td>
<td><p class="first">Specifies the name of an unprivileged user to which the child
process should switch before it starts accepting
connections.  This is a shortcut for specifying the user
run- time parameter.</p>
<p class="last">If specifying both a user and a group, the user should be
specified first.</p>
</td></tr>
<tr><td class="option-group">
<kbd><span class="option">-V</span></kbd></td>
<td>Display the version number and exit.</td></tr>
</tbody>
</table>
<p>-w min[,max[,timeout]]</p>
<blockquote>
<div><p>Start at least min but no more than max worker threads
with the specified idle timeout.  This is a shortcut for
specifying the thread_pool_min, thread_pool_max and
thread_pool_timeout run-time parameters.</p>
<p>If only one number is specified, thread_pool_min and
thread_pool_max are both set to this number, and
thread_pool_timeout has no effect.</p>
</div></blockquote>
<div class="section" id="hash-algorithms">
<h4>Hash Algorithms<a class="headerlink" href="#hash-algorithms" title="Permalink to this headline">¶</a></h4>
<p>The following hash algorithms are available:</p>
<dl class="docutils">
<dt>simple_list</dt>
<dd>A simple doubly-linked list.  Not recommended for production use.</dd>
<dt>classic[,buckets]</dt>
<dd>A standard hash table.  This is the default.  The hash key is the
CRC32 of the object's URL modulo the size of the hash table.  Each
table entry points to a list of elements which share the same hash
key. The buckets parameter specifies the number of entries in the
hash table.  The default is 16383.</dd>
<dt>critbit</dt>
<dd>A self-scaling tree structure. The default hash algorithm in 2.1. In
comparison to a more traditional B tree the critbit tree is almost
completely lockless.</dd>
</dl>
</div>
<div class="section" id="storage-types">
<h4>Storage Types<a class="headerlink" href="#storage-types" title="Permalink to this headline">¶</a></h4>
<p>The following storage types are available:</p>
<dl class="docutils">
<dt>malloc[,size]</dt>
<dd><p class="first">Storage for each object is allocated with malloc(3).</p>
<p>The size parameter specifies the maximum amount of memory varnishd will allocate.  The size is assumed to
be in bytes, unless followed by one of the following suffixes:</p>
<p>K, k    The size is expressed in kibibytes.</p>
<p>M, m    The size is expressed in mebibytes.</p>
<p>G, g    The size is expressed in gibibytes.</p>
<p>T, t    The size is expressed in tebibytes.</p>
<p class="last">The default size is unlimited.</p>
</dd>
<dt>file[,path[,size[,granularity]]]</dt>
<dd><p class="first">Storage for each object is allocated from an arena backed by a file.  This is the default.</p>
<p>The path parameter specifies either the path to the backing file or the path to a directory in which
varnishd will create the backing file.  The default is /tmp.</p>
<p>The size parameter specifies the size of the backing file.  The size is assumed to be in bytes, unless fol‐
lowed by one of the following suffixes:</p>
<p>K, k    The size is expressed in kibibytes.</p>
<p>M, m    The size is expressed in mebibytes.</p>
<p>G, g    The size is expressed in gibibytes.</p>
<p>T, t    The size is expressed in tebibytes.</p>
<p>%       The size is expressed as a percentage of the free space on the file system where it resides.</p>
<p>The default size is 50%.</p>
<p>If the backing file already exists, it will be truncated or expanded to the specified size.</p>
<p>Note that if varnishd has to create or expand the file, it will not pre-allocate the added space, leading
to fragmentation, which may adversely impact performance.  Pre-creating the storage file using dd(1) will
reduce fragmentation to a minimum.</p>
<p>The granularity parameter specifies the granularity of allocation.  All allocations are rounded up to this
size.  The size is assumed to be in bytes, unless followed by one of the suffixes described for size except
for %.</p>
<p class="last">The default size is the VM page size.  The size should be reduced if you have many small objects.</p>
</dd>
</dl>
<p>persistent,path,size {experimental}</p>
<blockquote>
<div><p>Persistent storage. Varnish will store objects in a file in a
manner that will secure the survival of <em>most</em> of the objects in
the event of a planned or unplanned shutdown of Varnish.</p>
<p>The path parameter specifies the path to the backing file. If
the file doesn't exist Varnish will create it.</p>
<p>The size parameter specifies the size of the backing file.  The
size is assumed to be in bytes, unless followed by one of the
following suffixes:</p>
<p>K, k    The size is expressed in kibibytes.</p>
<p>M, m    The size is expressed in mebibytes.</p>
<p>G, g    The size is expressed in gibibytes.</p>
<p>T, t    The size is expressed in tebibytes.</p>
<p>Varnish will split the file into logical <em>silos</em> and write to
the silos in the manner of a circular buffer. Only one silo will
be kept open at any given point in time. Full silos are
<em>sealed</em>. When Varnish starts after a shutdown it will discard
the content of any silo that isn't sealed.</p>
</div></blockquote>
</div>
<div class="section" id="transient-storage">
<h4>Transient Storage<a class="headerlink" href="#transient-storage" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div>If you name any of your storage backend &quot;Transient&quot; it will be
used for transient (short lived) objects. By default Varnish
would use an unlimited malloc backend for this.</div></blockquote>
</div>
<div class="section" id="management-interface">
<h4>Management Interface<a class="headerlink" href="#management-interface" title="Permalink to this headline">¶</a></h4>
<p>If the -T option was specified, varnishd will offer a command-line management interface on the specified address
and port.  The recommended way of connecting to the command-line management interface is through varnishadm(1).</p>
<p>The commands available are documented in varnish(7).</p>
</div>
<div class="section" id="run-time-parameters">
<h4>Run-Time Parameters<a class="headerlink" href="#run-time-parameters" title="Permalink to this headline">¶</a></h4>
<p>Runtime parameters are marked with shorthand flags to avoid repeating the same text over and over in the table
below.  The meaning of the flags are:</p>
<dl class="docutils">
<dt>experimental</dt>
<dd>We have no solid information about good/bad/optimal values for this parameter.  Feedback with experience
and observations are most welcome.</dd>
<dt>delayed</dt>
<dd>This parameter can be changed on the fly, but will not take effect immediately.</dd>
<dt>restart</dt>
<dd>The worker process must be stopped and restarted, before this parameter takes effect.</dd>
<dt>reload</dt>
<dd>The VCL programs must be reloaded for this parameter to take effect.</dd>
</dl>
<p>Here is a list of all parameters, current as of last time we remembered to update the manual page.  This text is
produced from the same text you will find in the CLI if you use the param.show command, so should there be a new
parameter which is not listed here, you can find the description using the CLI commands.</p>
<p>Be aware that on 32 bit systems, certain default values, such as sess_workspace (=16k) and thread_pool_stack
(=64k) are reduced relative to the values listed here, in order to conserve VM space.</p>
<dl class="docutils">
<dt>acceptor_sleep_decay</dt>
<dd><ul class="first simple">
<li>Default: 0.900</li>
<li>Flags: experimental</li>
</ul>
<p class="last">If we run out of resources, such as file descriptors or worker threads, the acceptor will sleep between accepts.
This parameter (multiplicatively) reduce the sleep duration for each succesfull accept. (ie: 0.9 = reduce by 10%)</p>
</dd>
<dt>acceptor_sleep_incr</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 0.001</li>
<li>Flags: experimental</li>
</ul>
<p class="last">If we run out of resources, such as file descriptors or worker threads, the acceptor will sleep between accepts.
This parameter control how much longer we sleep, each time we fail to accept a new connection.</p>
</dd>
<dt>acceptor_sleep_max</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 0.050</li>
<li>Flags: experimental</li>
</ul>
<p class="last">If we run out of resources, such as file descriptors or worker threads, the acceptor will sleep between accepts.
This parameter limits how long it can sleep between attempts to accept new connections.</p>
</dd>
<dt>auto_restart</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
</ul>
<p class="last">Restart child process automatically if it dies.</p>
</dd>
<dt>ban_dups</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
</ul>
<p class="last">Detect and eliminate duplicate bans.</p>
</dd>
<dt>ban_lurker_sleep</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 0.01</li>
</ul>
<p class="last">How long time does the ban lurker thread sleeps between successful attempts to push the last item up the ban  list.  It always sleeps a second when nothing can be done.
A value of zero disables the ban lurker.</p>
</dd>
<dt>between_bytes_timeout</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 60</li>
</ul>
<p class="last">Default timeout between bytes when receiving data from backend. We only wait for this many seconds between bytes before giving up. A value of 0 means it will never time out. VCL can override this default value for each backend request and backend request. This parameter does not apply to pipe.</p>
</dd>
<dt>cc_command</dt>
<dd><ul class="first simple">
<li>Default: exec gcc -std=gnu99  -pthread -fpic -shared -Wl,-x -o %o %s</li>
<li>Flags: must_reload</li>
</ul>
<p class="last">Command used for compiling the C source code to a dlopen(3) loadable object.  Any occurrence of %s in the string will be replaced with the source file name, and %o will be replaced with the output file name.</p>
</dd>
<dt>cli_buffer</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 8192</li>
</ul>
<p class="last">Size of buffer for CLI input.
You may need to increase this if you have big VCL files and use the vcl.inline CLI command.
NB: Must be specified with -p to have effect.</p>
</dd>
<dt>cli_timeout</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 10</li>
</ul>
<p class="last">Timeout for the childs replies to CLI requests from the master.</p>
</dd>
<dt>clock_skew</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 10</li>
</ul>
<p class="last">How much clockskew we are willing to accept between the backend and our own clock.</p>
</dd>
<dt>connect_timeout</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 0.7</li>
</ul>
<p class="last">Default connection timeout for backend connections. We only try to connect to the backend for this many seconds before giving up. VCL can override this default value for each backend and backend request.</p>
</dd>
<dt>critbit_cooloff</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 180.0</li>
<li>Flags:</li>
</ul>
<p class="last">How long time the critbit hasher keeps deleted objheads on the cooloff list.</p>
</dd>
<dt>default_grace</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 10</li>
<li>Flags: delayed</li>
</ul>
<p class="last">Default grace period.  We will deliver an object this long after it has expired, provided another thread is attempting to get a new copy.
Objects already cached will not be affected by changes made until they are fetched from the backend again.</p>
</dd>
<dt>default_keep</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 0</li>
<li>Flags: delayed</li>
</ul>
<p class="last">Default keep period.  We will keep a useless object around this long, making it available for conditional backend fetches.  That means that the object will be removed from the cache at the end of ttl+grace+keep.</p>
</dd>
<dt>default_ttl</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 120</li>
</ul>
<p class="last">The TTL assigned to objects if neither the backend nor the VCL code assigns one.
Objects already cached will not be affected by changes made until they are fetched from the backend again.
To force an immediate effect at the expense of a total flush of the cache use &quot;ban.url .&quot;</p>
</dd>
<dt>diag_bitmap</dt>
<dd><ul class="first simple">
<li>Units: bitmap</li>
<li>Default: 0</li>
</ul>
<p>Bitmap controlling diagnostics code:</p>
<div class="highlight-python"><pre>0x00000001 - CNT_Session states.
0x00000002 - workspace debugging.
0x00000004 - kqueue debugging.
0x00000008 - mutex logging.
0x00000010 - mutex contests.
0x00000020 - waiting list.
0x00000040 - object workspace.
0x00001000 - do not core-dump child process.
0x00002000 - only short panic message.
0x00004000 - panic to stderr.
0x00010000 - synchronize shmlog.
0x00020000 - synchronous start of persistence.
0x00040000 - release VCL early.
0x80000000 - do edge-detection on digest.</pre>
</div>
<p class="last">Use 0x notation and do the bitor in your head :-)</p>
</dd>
<dt>esi_syntax</dt>
<dd><ul class="first simple">
<li>Units: bitmap</li>
<li>Default: 0</li>
</ul>
<p>Bitmap controlling ESI parsing code:</p>
<div class="highlight-python"><pre>0x00000001 - Don't check if it looks like XML
0x00000002 - Ignore non-esi elements
0x00000004 - Emit parsing debug records
0x00000008 - Force-split parser input (debugging)</pre>
</div>
<p class="last">Use 0x notation and do the bitor in your head :-)</p>
</dd>
<dt>expiry_sleep</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 1</li>
</ul>
<p class="last">How long the expiry thread sleeps when there is nothing for it to do.</p>
</dd>
<dt>fetch_chunksize</dt>
<dd><ul class="first simple">
<li>Units: kilobytes</li>
<li>Default: 128</li>
<li>Flags: experimental</li>
</ul>
<p class="last">The default chunksize used by fetcher. This should be bigger than the majority of objects with short TTLs.
Internal limits in the storage_file module makes increases above 128kb a dubious idea.</p>
</dd>
<dt>fetch_maxchunksize</dt>
<dd><ul class="first simple">
<li>Units: kilobytes</li>
<li>Default: 262144</li>
<li>Flags: experimental</li>
</ul>
<p class="last">The maximum chunksize we attempt to allocate from storage. Making this too large may cause delays and storage fragmentation.</p>
</dd>
<dt>first_byte_timeout</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 60</li>
</ul>
<p class="last">Default timeout for receiving first byte from backend. We only wait for this many seconds for the first byte before giving up. A value of 0 means it will never time out. VCL can override this default value for each backend and backend request. This parameter does not apply to pipe.</p>
</dd>
<dt>group</dt>
<dd><ul class="first simple">
<li>Default: magic</li>
<li>Flags: must_restart</li>
</ul>
<p class="last">The unprivileged group to run as.</p>
</dd>
<dt>gzip_level</dt>
<dd><ul class="first simple">
<li>Default: 6</li>
</ul>
<p class="last">Gzip compression level: 0=debug, 1=fast, 9=best</p>
</dd>
<dt>gzip_memlevel</dt>
<dd><ul class="first simple">
<li>Default: 8</li>
</ul>
<p class="last">Gzip memory level 1=slow/least, 9=fast/most compression.
Memory impact is 1=1k, 2=2k, ... 9=256k.</p>
</dd>
<dt>gzip_stack_buffer</dt>
<dd><ul class="first simple">
<li>Units: Bytes</li>
<li>Default: 32768</li>
<li>Flags: experimental</li>
</ul>
<p class="last">Size of stack buffer used for gzip processing.
The stack buffers are used for in-transit data, for instance gunzip'ed data being sent to a client.Making this space to small results in more overhead, writes to sockets etc, making it too big is probably just a waste of memory.</p>
</dd>
<dt>gzip_tmp_space</dt>
<dd><ul class="first simple">
<li>Default: 0</li>
<li>Flags: experimental</li>
</ul>
<p>Where temporary space for gzip/gunzip is allocated:</p>
<div class="highlight-python"><pre>0 - malloc
1 - session workspace
2 - thread workspace</pre>
</div>
<p class="last">If you have much gzip/gunzip activity, it may be an advantage to use workspace for these allocations to reduce malloc activity.  Be aware that gzip needs 256+KB and gunzip needs 32+KB of workspace (64+KB if ESI processing).</p>
</dd>
<dt>gzip_window</dt>
<dd><ul class="first simple">
<li>Default: 15</li>
</ul>
<p class="last">Gzip window size 8=least, 15=most compression.
Memory impact is 8=1k, 9=2k, ... 15=128k.</p>
</dd>
<dt>http_gzip_support</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
<li>Flags: experimental</li>
</ul>
<p>Enable gzip support. When enabled Varnish will compress uncompressed objects before they are stored in the cache. If a client does not support gzip encoding Varnish will uncompress compressed objects on demand. Varnish will also rewrite the Accept-Encoding header of clients indicating support for gzip to:</p>
<p>Accept-Encoding: gzip</p>
<p class="last">Clients that do not support gzip will have their Accept-Encoding header removed. For more information on how gzip is implemented please see the chapter on gzip in the Varnish reference.</p>
</dd>
<dt>http_max_hdr</dt>
<dd><ul class="first simple">
<li>Units: header lines</li>
<li>Default: 64</li>
</ul>
<p class="last">Maximum number of HTTP headers we will deal with in client request or backend reponses.  Note that the first line occupies five header fields.
This paramter does not influence storage consumption, objects allocate exact space for the headers they store.</p>
</dd>
<dt>http_range_support</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
<li>Flags: experimental</li>
</ul>
<p class="last">Enable support for HTTP Range headers.</p>
</dd>
<dt>http_req_hdr_len</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 8192</li>
</ul>
<p class="last">Maximum length of any HTTP client request header we will allow.  The limit is inclusive its continuation lines.</p>
</dd>
<dt>http_req_size</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 32768</li>
</ul>
<p class="last">Maximum number of bytes of HTTP client request we will deal with.  This is a limit on all bytes up to the double blank line which ends the HTTP request.
The memory for the request is allocated from the session workspace (param: sess_workspace) and this parameter limits how much of that the request is allowed to take up.</p>
</dd>
<dt>http_resp_hdr_len</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 8192</li>
</ul>
<p class="last">Maximum length of any HTTP backend response header we will allow.  The limit is inclusive its continuation lines.</p>
</dd>
<dt>http_resp_size</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 32768</li>
</ul>
<p class="last">Maximum number of bytes of HTTP backend resonse we will deal with.  This is a limit on all bytes up to the double blank line which ends the HTTP request.
The memory for the request is allocated from the worker workspace (param: sess_workspace) and this parameter limits how much of that the request is allowed to take up.</p>
</dd>
<dt>listen_address</dt>
<dd><ul class="first simple">
<li>Default: :80</li>
<li>Flags: must_restart</li>
</ul>
<p class="last">Whitespace separated list of network endpoints where Varnish will accept requests.
Possible formats: host, host:port, :port</p>
</dd>
<dt>listen_depth</dt>
<dd><ul class="first simple">
<li>Units: connections</li>
<li>Default: 1024</li>
<li>Flags: must_restart</li>
</ul>
<p class="last">Listen queue depth.</p>
</dd>
<dt>log_hashstring</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
</ul>
<p class="last">Log the hash string components to shared memory log.</p>
</dd>
<dt>log_local_address</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: off</li>
</ul>
<p class="last">Log the local address on the TCP connection in the SessionOpen shared memory record.</p>
</dd>
<dt>lru_interval</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 2</li>
<li>Flags: experimental</li>
</ul>
<p class="last">Grace period before object moves on LRU list.
Objects are only moved to the front of the LRU list if they have not been moved there already inside this timeout period.  This reduces the amount of lock operations necessary for LRU list access.</p>
</dd>
<dt>max_esi_depth</dt>
<dd><ul class="first simple">
<li>Units: levels</li>
<li>Default: 5</li>
</ul>
<p class="last">Maximum depth of esi:include processing.</p>
</dd>
<dt>max_restarts</dt>
<dd><ul class="first simple">
<li>Units: restarts</li>
<li>Default: 4</li>
</ul>
<p class="last">Upper limit on how many times a request can restart.
Be aware that restarts are likely to cause a hit against the backend, so don't increase thoughtlessly.</p>
</dd>
<dt>nuke_limit</dt>
<dd><ul class="first simple">
<li>Units: allocations</li>
<li>Default: 50</li>
<li>Flags: experimental</li>
</ul>
<p class="last">Maximum number of objects we attempt to nuke in orderto make space for a object body.</p>
</dd>
<dt>ping_interval</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 3</li>
<li>Flags: must_restart</li>
</ul>
<p class="last">Interval between pings from parent to child.
Zero will disable pinging entirely, which makes it possible to attach a debugger to the child.</p>
</dd>
<dt>pipe_timeout</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 60</li>
</ul>
<p class="last">Idle timeout for PIPE sessions. If nothing have been received in either direction for this many seconds, the session is closed.</p>
</dd>
<dt>prefer_ipv6</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: off</li>
</ul>
<p class="last">Prefer IPv6 address when connecting to backends which have both IPv4 and IPv6 addresses.</p>
</dd>
<dt>queue_max</dt>
<dd><ul class="first simple">
<li>Units: %</li>
<li>Default: 100</li>
<li>Flags: experimental</li>
</ul>
<p>Percentage permitted queue length.</p>
<p class="last">This sets the ratio of queued requests to worker threads, above which sessions will be dropped instead of queued.</p>
</dd>
<dt>rush_exponent</dt>
<dd><ul class="first simple">
<li>Units: requests per request</li>
<li>Default: 3</li>
<li>Flags: experimental</li>
</ul>
<p class="last">How many parked request we start for each completed request on the object.
NB: Even with the implict delay of delivery, this parameter controls an exponential increase in number of worker threads.</p>
</dd>
<dt>saintmode_threshold</dt>
<dd><ul class="first simple">
<li>Units: objects</li>
<li>Default: 10</li>
<li>Flags: experimental</li>
</ul>
<p class="last">The maximum number of objects held off by saint mode before no further will be made to the backend until one times out.  A value of 0 disables saintmode.</p>
</dd>
<dt>send_timeout</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 60</li>
<li>Flags: delayed</li>
</ul>
<p class="last">Send timeout for client connections. If the HTTP response hasn't been transmitted in this many
seconds the session is closed.
See setsockopt(2) under SO_SNDTIMEO for more information.</p>
</dd>
<dt>sess_timeout</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 5</li>
</ul>
<p class="last">Idle timeout for persistent sessions. If a HTTP request has not been received in this many seconds, the session is closed.</p>
</dd>
<dt>sess_workspace</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 65536</li>
<li>Flags: delayed</li>
</ul>
<p class="last">Bytes of HTTP protocol workspace allocated for sessions. This space must be big enough for the entire HTTP protocol header and any edits done to it in the VCL code.
Minimum is 1024 bytes.</p>
</dd>
<dt>session_linger</dt>
<dd><ul class="first simple">
<li>Units: ms</li>
<li>Default: 50</li>
<li>Flags: experimental</li>
</ul>
<p class="last">How long time the workerthread lingers on the session to see if a new request appears right away.
If sessions are reused, as much as half of all reuses happen within the first 100 msec of the previous request completing.
Setting this too high results in worker threads not doing anything for their keep, setting it too low just means that more sessions take a detour around the waiter.</p>
</dd>
<dt>session_max</dt>
<dd><ul class="first simple">
<li>Units: sessions</li>
<li>Default: 100000</li>
</ul>
<p class="last">Maximum number of sessions we will allocate before just dropping connections.
This is mostly an anti-DoS measure, and setting it plenty high should not hurt, as long as you have the memory for it.</p>
</dd>
<dt>shm_reclen</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 255</li>
</ul>
<p class="last">Maximum number of bytes in SHM log record.
Maximum is 65535 bytes.</p>
</dd>
<dt>shm_workspace</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 8192</li>
<li>Flags: delayed</li>
</ul>
<p class="last">Bytes of shmlog workspace allocated for worker threads. If too big, it wastes some ram, if too small it causes needless flushes of the SHM workspace.
These flushes show up in stats as &quot;SHM flushes due to overflow&quot;.
Minimum is 4096 bytes.</p>
</dd>
<dt>shortlived</dt>
<dd><ul class="first simple">
<li>Units: s</li>
<li>Default: 10.0</li>
</ul>
<p class="last">Objects created with TTL shorter than this are always put in transient storage.</p>
</dd>
<dt>syslog_cli_traffic</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
</ul>
<p class="last">Log all CLI traffic to syslog(LOG_INFO).</p>
</dd>
<dt>thread_pool_add_delay</dt>
<dd><ul class="first simple">
<li>Units: milliseconds</li>
<li>Default: 2</li>
</ul>
<p>Wait at least this long between creating threads.</p>
<p>Setting this too long results in insuffient worker threads.</p>
<p class="last">Setting this too short increases the risk of worker thread pile-up.</p>
</dd>
<dt>thread_pool_add_threshold</dt>
<dd><ul class="first simple">
<li>Units: requests</li>
<li>Default: 2</li>
<li>Flags: experimental</li>
</ul>
<p>Overflow threshold for worker thread creation.</p>
<p>Setting this too low, will result in excess worker threads, which is generally a bad idea.</p>
<p class="last">Setting it too high results in insuffient worker threads.</p>
</dd>
<dt>thread_pool_fail_delay</dt>
<dd><ul class="first simple">
<li>Units: milliseconds</li>
<li>Default: 200</li>
<li>Flags: experimental</li>
</ul>
<p>Wait at least this long after a failed thread creation before trying to create another thread.</p>
<p>Failure to create a worker thread is often a sign that  the end is near, because the process is running out of RAM resources for thread stacks.
This delay tries to not rush it on needlessly.</p>
<p>If thread creation failures are a problem, check that thread_pool_max is not too high.</p>
<p class="last">It may also help to increase thread_pool_timeout and thread_pool_min, to reduce the rate at which treads are destroyed and later recreated.</p>
</dd>
<dt>thread_pool_max</dt>
<dd><ul class="first simple">
<li>Units: threads</li>
<li>Default: 500</li>
<li>Flags: delayed, experimental</li>
</ul>
<p>The maximum number of worker threads in each pool.</p>
<p class="last">Do not set this higher than you have to, since excess worker threads soak up RAM and CPU and generally just get in the way of getting work done.</p>
</dd>
<dt>thread_pool_min</dt>
<dd><ul class="first simple">
<li>Units: threads</li>
<li>Default: 5</li>
<li>Flags: delayed, experimental</li>
</ul>
<p>The minimum number of worker threads in each pool.</p>
<p>Increasing this may help ramp up faster from low load situations where threads have expired.</p>
<p class="last">Minimum is 2 threads.</p>
</dd>
<dt>thread_pool_purge_delay</dt>
<dd><ul class="first simple">
<li>Units: milliseconds</li>
<li>Default: 1000</li>
<li>Flags: delayed, experimental</li>
</ul>
<p>Wait this long between purging threads.</p>
<p>This controls the decay of thread pools when idle(-ish).</p>
<p class="last">Minimum is 100 milliseconds.</p>
</dd>
<dt>thread_pool_stack</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: -1</li>
<li>Flags: experimental</li>
</ul>
<p class="last">Worker thread stack size.
On 32bit systems you may need to tweak this down to fit many threads into the limited address space.</p>
</dd>
<dt>thread_pool_timeout</dt>
<dd><ul class="first simple">
<li>Units: seconds</li>
<li>Default: 300</li>
<li>Flags: delayed, experimental</li>
</ul>
<p>Thread idle threshold.</p>
<p>Threads in excess of thread_pool_min, which have been idle for at least this long are candidates for purging.</p>
<p class="last">Minimum is 1 second.</p>
</dd>
<dt>thread_pool_workspace</dt>
<dd><ul class="first simple">
<li>Units: bytes</li>
<li>Default: 65536</li>
<li>Flags: delayed</li>
</ul>
<p class="last">Bytes of HTTP protocol workspace allocated for worker threads. This space must be big enough for the backend request and responses, and response to the client plus any other memory needs in the VCL code.Minimum is 1024 bytes.</p>
</dd>
<dt>thread_pools</dt>
<dd><ul class="first simple">
<li>Units: pools</li>
<li>Default: 2</li>
<li>Flags: delayed, experimental</li>
</ul>
<p>Number of worker thread pools.</p>
<p>Increasing number of worker pools decreases lock contention.</p>
<p>Too many pools waste CPU and RAM resources, and more than one pool for each CPU is probably detrimal to performance.</p>
<p class="last">Can be increased on the fly, but decreases require a restart to take effect.</p>
</dd>
<dt>thread_stats_rate</dt>
<dd><ul class="first simple">
<li>Units: requests</li>
<li>Default: 10</li>
<li>Flags: experimental</li>
</ul>
<p class="last">Worker threads accumulate statistics, and dump these into the global stats counters if the lock is free when they finish a request.
This parameters defines the maximum number of requests a worker thread may handle, before it is forced to dump its accumulated stats into the global counters.</p>
</dd>
<dt>user</dt>
<dd><ul class="first simple">
<li>Default: magic</li>
<li>Flags: must_restart</li>
</ul>
<p class="last">The unprivileged user to run as.  Setting this will also set &quot;group&quot; to the specified user's primary group.</p>
</dd>
<dt>vcc_err_unref</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: on</li>
</ul>
<p class="last">Unreferenced VCL objects result in error.</p>
</dd>
<dt>vcl_dir</dt>
<dd><ul class="first simple">
<li>Default: /usr/local/etc/varnish</li>
</ul>
<p class="last">Directory from which relative VCL filenames (vcl.load and include) are opened.</p>
</dd>
<dt>vcl_trace</dt>
<dd><ul class="first simple">
<li>Units: bool</li>
<li>Default: off</li>
</ul>
<p class="last">Trace VCL execution in the shmlog.
Enabling this will allow you to see the path each request has taken through the VCL program.
This generates a lot of logrecords so it is off by default.</p>
</dd>
<dt>vmod_dir</dt>
<dd><ul class="first simple">
<li>Default: /usr/local/lib/varnish/vmods</li>
</ul>
<p class="last">Directory where VCL modules are to be found.</p>
</dd>
<dt>waiter</dt>
<dd><ul class="first simple">
<li>Default: default</li>
<li>Flags: must_restart, experimental</li>
</ul>
<p class="last">Select the waiter kernel interface.</p>
</dd>
</dl>
</div>
</div>
<div class="section" id="see-also">
<h3>SEE ALSO<a class="headerlink" href="#see-also" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>varnish-cli(7)</li>
<li>varnishlog(1)</li>
<li>varnishhist(1)</li>
<li>varnishncsa(1)</li>
<li>varnishstat(1)</li>
<li>varnishtop(1)</li>
<li>vcl(7)</li>
</ul>
</div>
<div class="section" id="history">
<h3>HISTORY<a class="headerlink" href="#history" title="Permalink to this headline">¶</a></h3>
<p>The varnishd daemon was developed by Poul-Henning Kamp in cooperation
with Verdens Gang AS, Varnish Software AS and Varnish Software.</p>
<p>This manual page was written by Dag-Erling Smørgrav with updates by
Stig Sandbeck Mathisen ⟨ssm&#64;debian.org⟩</p>
</div>
<div class="section" id="copyright">
<h3>COPYRIGHT<a class="headerlink" href="#copyright" title="Permalink to this headline">¶</a></h3>
<p>This document is licensed under the same licence as Varnish
itself. See LICENCE for details.</p>
<ul class="simple">
<li>Copyright (c) 2007-2011 Varnish Software AS</li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">varnishd</a><ul>
<li><a class="reference internal" href="#http-accelerator-daemon">HTTP accelerator daemon</a><ul>
<li><a class="reference internal" href="#synopsis">SYNOPSIS</a></li>
<li><a class="reference internal" href="#description">DESCRIPTION</a></li>
<li><a class="reference internal" href="#options">OPTIONS</a><ul>
<li><a class="reference internal" href="#hash-algorithms">Hash Algorithms</a></li>
<li><a class="reference internal" href="#storage-types">Storage Types</a></li>
<li><a class="reference internal" href="#transient-storage">Transient Storage</a></li>
<li><a class="reference internal" href="#management-interface">Management Interface</a></li>
<li><a class="reference internal" href="#run-time-parameters">Run-Time Parameters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#see-also">SEE ALSO</a></li>
<li><a class="reference internal" href="#history">HISTORY</a></li>
<li><a class="reference internal" href="#copyright">COPYRIGHT</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="varnishadm.html"
                        title="previous chapter">varnishadm</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="varnishhist.html"
                        title="next chapter">varnishhist</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/reference/varnishd.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="varnishhist.html" title="varnishhist"
             >next</a> |</li>
        <li class="right" >
          <a href="varnishadm.html" title="varnishadm"
             >previous</a> |</li>
        <li><a href="../index.html">Varnish version 3.0.2 documentation</a> &raquo;</li>
          <li><a href="index.html" >The Varnish Reference Manual</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2010, Varnish Project.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.0.7.
    </div>
  </body>
</html>